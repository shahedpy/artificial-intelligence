# Artificial Intelligence

## Confusion Matrix

A confusion matrix is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known.
- It allows the visualization of the performance of an algorithm.
- We compare each class with every other class and see how many samples are misclassified.
- We actually come across several key metrics that are very important in the field of machine learning.

### Confusion Matrix Classification

- **True Positive(TP):** You projected positive and its turn out to be true. For example, you had predicted that France would win the world cup, and it won.
- **True Negative(TN):** When you predicted negative, and it's true. You had predicted that England would not win and it lost.
- **False Positive(FP):** Your prediction is positive, and it is false. You had predicted that England would win, but it lost.
- **False Negative(FN):** Your prediction is negative, and result it is also false. You had predicted that France would not win, but it won.

